{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84a51193ebc99485",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU06 - Dealing with Data Problems\n",
    "\n",
    "This notebook has exercises covering the following topics:\n",
    "\n",
    "- Tidy Data\n",
    "- Data Entry Problems\n",
    "- Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f69d2e900572be7a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7796ff89561e1599",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The dataset that we'll use for these exercises comes from the World Health Organisation, and records the counts of confirmed tuberculosis cases by country, year (between 1980 and 2008), and demographic group.\n",
    "The demographic groups are broken down by sex (m, f) and age (0–14, 15–25, 25–34, 35–44, 45–54, 55–64, 65+, unknown).\n",
    "\n",
    "But as you will see, this dataset doesn't follow the Tidy Data Principle.\n",
    "\n",
    "In the following exercises, we will clean it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3080c578932750e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "First let's read the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-001eae7e09f6322f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>new_sp_m014</th>\n",
       "      <th>new_sp_m1524</th>\n",
       "      <th>new_sp_m2534</th>\n",
       "      <th>new_sp_m3544</th>\n",
       "      <th>new_sp_m4554</th>\n",
       "      <th>new_sp_m5564</th>\n",
       "      <th>new_sp_m65</th>\n",
       "      <th>new_sp_mu</th>\n",
       "      <th>new_sp_f014</th>\n",
       "      <th>new_sp_f1524</th>\n",
       "      <th>new_sp_f2534</th>\n",
       "      <th>new_sp_f3544</th>\n",
       "      <th>new_sp_f4554</th>\n",
       "      <th>new_sp_f5564</th>\n",
       "      <th>new_sp_f65</th>\n",
       "      <th>new_sp_fu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>1990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AD</td>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AD</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AD</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  new_sp_m014  new_sp_m1524  new_sp_m2534  new_sp_m3544  \\\n",
       "0      AD  1989          NaN           NaN           NaN           NaN   \n",
       "1      AD  1990          NaN           NaN           NaN           NaN   \n",
       "2      AD  1991          NaN           NaN           NaN           NaN   \n",
       "3      AD  1992          NaN           NaN           NaN           NaN   \n",
       "4      AD  1993          NaN           NaN           NaN           NaN   \n",
       "5      AD  1994          NaN           NaN           NaN           NaN   \n",
       "6      AD  1996          0.0           0.0           0.0           4.0   \n",
       "7      AD  1997          0.0           0.0           1.0           2.0   \n",
       "8      AD  1998          0.0           0.0           0.0           1.0   \n",
       "9      AD  1999          0.0           0.0           0.0           1.0   \n",
       "\n",
       "   new_sp_m4554  new_sp_m5564  new_sp_m65  new_sp_mu  new_sp_f014  \\\n",
       "0           NaN           NaN         NaN        NaN          NaN   \n",
       "1           NaN           NaN         NaN        NaN          NaN   \n",
       "2           NaN           NaN         NaN        NaN          NaN   \n",
       "3           NaN           NaN         NaN        NaN          NaN   \n",
       "4           NaN           NaN         NaN        NaN          NaN   \n",
       "5           NaN           NaN         NaN        NaN          NaN   \n",
       "6           1.0           0.0         0.0        NaN          0.0   \n",
       "7           2.0           1.0         6.0        NaN          0.0   \n",
       "8           0.0           0.0         0.0        NaN          NaN   \n",
       "9           1.0           0.0         0.0        NaN          0.0   \n",
       "\n",
       "   new_sp_f1524  new_sp_f2534  new_sp_f3544  new_sp_f4554  new_sp_f5564  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "5           NaN           NaN           NaN           NaN           NaN   \n",
       "6           1.0           1.0           0.0           0.0           1.0   \n",
       "7           1.0           2.0           3.0           0.0           0.0   \n",
       "8           NaN           NaN           NaN           NaN           NaN   \n",
       "9           0.0           0.0           1.0           0.0           0.0   \n",
       "\n",
       "   new_sp_f65  new_sp_fu  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "5         NaN        NaN  \n",
       "6         0.0        NaN  \n",
       "7         1.0        NaN  \n",
       "8         NaN        NaN  \n",
       "9         0.0        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'tb.csv'))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c1385558c47a3b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create a list with the column names that refer to the demographic groups data (i.e, those that start with `new_sp_`).\n",
    "\n",
    "Call the list `demo_group_data`. The values in list should be in the same order as they are in the dataframe's columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_group_data = list(df[[i for i in df.columns if \"new_sp_\" in i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-188948d13a5b357c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a list with the demographic groups data\n",
    "# demo_group_data = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "demo_group_data = list(df[[col for col in df.columns if \"new_sp_\" in col]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d828d2d6cb20d296",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "first_element_hash = 'c8ae9368386d7c77204db0840e77d432aff39941d6f42407b0164028b0bdd5c6'\n",
    "entire_list_hash = '11db8cc5591bcd9757e052b44e7b1a5ccd4f2de2e5c3130d5437834ea021aa78'\n",
    "\n",
    "assert isinstance(demo_group_data, list), \"demo_group_data should be a list.\"\n",
    "\n",
    "assert len(demo_group_data) == 16, \"demo_group_data doesn't have the right number of elements.\"\n",
    "\n",
    "error_msg = 'The first element of the list is not correct.'\n",
    "assert first_element_hash == hashlib.sha256(bytes(demo_group_data[0], encoding='utf8')).hexdigest(), error_msg\n",
    "\n",
    "error_msg = 'The list is not correct.'\n",
    "assert entire_list_hash == hashlib.sha256(json.dumps(demo_group_data).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4d41aac166a7fa2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Create a new dataframe, that is the result of changing `df` so that it has 4 columns:\n",
    "- country\n",
    "- year\n",
    "- demo_group\n",
    "- cases\n",
    "\n",
    "The values in the demo_group column should be exactly the ones that we currently have as column names.\n",
    "\n",
    "The new dataframe should be called `df_tidy_1`.\n",
    "\n",
    "Hint: use the answer from **Exercise 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e7fa8d07fe433cc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a new version of df that doesn't have variable values as columns\n",
    "# df_tidy_1 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df_tidy_1 = pd.melt(df, id_vars= ['country','year'],  value_vars =  demo_group_data, var_name = 'demo_group', value_name= 'cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-640d2b3b55c2cc39",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "column_names_hash = '8a5277b30342779427d2bf91bdbe9669975eecaf85c3560103367a75af3d971c'\n",
    "dataframe_shape_hash = 'd28d50e42c0b9b03762856921319b41c42f7fa4d1b5da5c5b4b84d716eff3a9c'\n",
    "dataframe_hash = '1c564c7ad9e350444637e70de9af00877e99dc5518dc130664617e4ce51b1a42'\n",
    "\n",
    "assert isinstance(df_tidy_1, pd.DataFrame), \"df_tidy_1 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_1.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_1.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_1.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-94385579b7ec22e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Now, take a look at the values in column `demo_group`.\n",
    "\n",
    "They all start with a meaningless \"new_sp_\" string, so we will remove it.\n",
    "\n",
    "Create a new dataframe `df_tidy_2`, that is a copy of `df_tidy_1`, but where the `demo_group` column no longer has the \"new_sp_\" in each value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a0680701ef7a9e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a new version of df_tidy_1 that doesn't have \"new_sp_\" in the demo_group column\n",
    "# df_tidy_2 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df_tidy_1['demo_group'] = df_tidy_1['demo_group'].str.replace('new_sp_', '')\n",
    "df_tidy_2 = pd.DataFrame(df_tidy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b63a0ff46979395c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names_hash = '8a5277b30342779427d2bf91bdbe9669975eecaf85c3560103367a75af3d971c'\n",
    "dataframe_shape_hash = 'd28d50e42c0b9b03762856921319b41c42f7fa4d1b5da5c5b4b84d716eff3a9c'\n",
    "dataframe_hash = '5d7508a0b5cda0e5f4cb530f5922199576d255ac7340d9fc1c89b28b5d6b355d'\n",
    "\n",
    "assert isinstance(df_tidy_2, pd.DataFrame), \"df_tidy_2 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_2.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_2.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_2.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc32120e82748b65",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "As you may have noticed, our dataset still has a problem. The `demo_group` column has data that in fact represents two variables: `gender` and `age`.\n",
    "\n",
    "So our end goal will be to replace the `demo_group` column with the two new columns.\n",
    "\n",
    "On this exercise, create a new dataframe `df_tidy_3`, that is a copy of `df_tidy_2`, but has a new column `gender`, which has the first letter of column `demo_group` (m/f).\n",
    "\n",
    "Hint: you may need to search for this one online, as you'll need a string method that we didn't cover in the Learning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9c176a8e3461c10",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a new version of df_tidy_2 that has a new column gender\n",
    "# df_tidy_3 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df_tidy_2['gender'] = df_tidy_2['demo_group'].astype(str).str[0]\n",
    "df_tidy_3 = pd.DataFrame(df_tidy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c06912eb8d895afc",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "column_names_hash = 'a3efb4e4eb3a43fa947a95032395ccc21d2cc3715a8d359e4c711132f4b837e0'\n",
    "dataframe_shape_hash = '78cdfddff871199ede18988405d0daf7c840512ff0bdb01168d3f85394618ef8'\n",
    "dataframe_hash = '282c81e0a303c5515386d4d78bbd2307377447e9f14ea35d6bcbdc2ec720b1bb'\n",
    "\n",
    "assert isinstance(df_tidy_3, pd.DataFrame), \"df_tidy_3 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_3.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_3.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_3.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8084477a20cda1ba",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Now we want to create the column `age` and get rid of column `demo_group`.\n",
    "\n",
    "On this exercise, create a new dataframe `df_tidy_4`, that is a copy of `df_tidy_3`, but has a new column `age`, which is the same as column `demo_group`, except that it has the first letter removed.\n",
    "\n",
    "We also want to get rid of column `demo_group`, so make sure the new dataframe doesn't have it!\n",
    "\n",
    "Hint: you may need to search for this one online, as you'll need a string method that we didn't cover in the Learning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a1b561a9c60b159",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a new version of df_tidy_3 that has a new column age, and doesn't have column demo_group\n",
    "# df_tidy_4 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df_tidy_3['age'] = df_tidy_2['demo_group'].astype(str).str[1:]\n",
    "df_tidy_3 = df_tidy_3.drop(['demo_group'], axis = 1)\n",
    "df_tidy_4 = pd.DataFrame(df_tidy_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-52d4f44d3697b15a",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "column_names_hash = 'ab05d50deb2a842b806a607ad26166c82f91960bd9dae704d8a11ff78fb60860'\n",
    "dataframe_shape_hash = '78cdfddff871199ede18988405d0daf7c840512ff0bdb01168d3f85394618ef8'\n",
    "dataframe_hash = 'f534bc81fdd39b7a79c0630d6a3a0728b89c40d6c95bf297d94e537bfa305f84'\n",
    "\n",
    "assert isinstance(df_tidy_4, pd.DataFrame), \"df_tidy_4 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_4.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_4.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_4.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8bbd3fc63242f26",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 6\n",
    "\n",
    "If you take a look at the age values, they are quite hard to understand... \n",
    "Let's make those easier to grasp!\n",
    "\n",
    "Create a new dataframe `df_tidy_5`, where the `age` column has more understandable values.\n",
    "\n",
    "We want that each age interval is separated by a `-`. For instance, `014` should be replaced with `0-14`.\n",
    "We also want the last age group to be represented as `65+`. The unknown values `u` can be left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a5e28ea0faa0992",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      country  year  cases gender   age\n",
      "0          AD  1989    NaN      m  0-14\n",
      "1          AD  1990    NaN      m  0-14\n",
      "2          AD  1991    NaN      m  0-14\n",
      "3          AD  1992    NaN      m  0-14\n",
      "4          AD  1993    NaN      m  0-14\n",
      "5          AD  1994    NaN      m  0-14\n",
      "6          AD  1996    0.0      m  0-14\n",
      "7          AD  1997    0.0      m  0-14\n",
      "8          AD  1998    0.0      m  0-14\n",
      "9          AD  1999    0.0      m  0-14\n",
      "10         AD  2000    0.0      m  0-14\n",
      "11         AD  2001    0.0      m  0-14\n",
      "12         AD  2002    0.0      m  0-14\n",
      "13         AD  2003    0.0      m  0-14\n",
      "14         AD  2004    0.0      m  0-14\n",
      "15         AD  2005    0.0      m  0-14\n",
      "16         AD  2006    0.0      m  0-14\n",
      "17         AD  2007    NaN      m  0-14\n",
      "18         AD  2008    0.0      m  0-14\n",
      "19         AE  1980    NaN      m  0-14\n",
      "20         AE  1981    NaN      m  0-14\n",
      "21         AE  1982    NaN      m  0-14\n",
      "22         AE  1983    NaN      m  0-14\n",
      "23         AE  1984    NaN      m  0-14\n",
      "24         AE  1985    NaN      m  0-14\n",
      "25         AE  1986    NaN      m  0-14\n",
      "26         AE  1987    NaN      m  0-14\n",
      "27         AE  1988    NaN      m  0-14\n",
      "28         AE  1989    NaN      m  0-14\n",
      "29         AE  1990    NaN      m  0-14\n",
      "...       ...   ...    ...    ...   ...\n",
      "92274      ZM  2008    0.0      f     u\n",
      "92275      ZW  1980    NaN      f     u\n",
      "92276      ZW  1981    NaN      f     u\n",
      "92277      ZW  1982    NaN      f     u\n",
      "92278      ZW  1983    NaN      f     u\n",
      "92279      ZW  1984    NaN      f     u\n",
      "92280      ZW  1985    NaN      f     u\n",
      "92281      ZW  1986    NaN      f     u\n",
      "92282      ZW  1987    NaN      f     u\n",
      "92283      ZW  1988    NaN      f     u\n",
      "92284      ZW  1989    NaN      f     u\n",
      "92285      ZW  1990    NaN      f     u\n",
      "92286      ZW  1991    NaN      f     u\n",
      "92287      ZW  1992    NaN      f     u\n",
      "92288      ZW  1993    NaN      f     u\n",
      "92289      ZW  1994    NaN      f     u\n",
      "92290      ZW  1995    NaN      f     u\n",
      "92291      ZW  1996    NaN      f     u\n",
      "92292      ZW  1997    NaN      f     u\n",
      "92293      ZW  1998    NaN      f     u\n",
      "92294      ZW  1999    NaN      f     u\n",
      "92295      ZW  2000    NaN      f     u\n",
      "92296      ZW  2001    NaN      f     u\n",
      "92297      ZW  2002    NaN      f     u\n",
      "92298      ZW  2003    NaN      f     u\n",
      "92299      ZW  2004    NaN      f     u\n",
      "92300      ZW  2005    NaN      f     u\n",
      "92301      ZW  2006    NaN      f     u\n",
      "92302      ZW  2007    NaN      f     u\n",
      "92303      ZW  2008    0.0      f     u\n",
      "\n",
      "[92304 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new version of df_tidy_4 where the age values are more understandable\n",
    "# df_tidy_5 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "ca = []\n",
    "for i in df_tidy_4['age']:\n",
    "    if i == 'u':\n",
    "        ca.append(i)\n",
    "    elif i == '65':\n",
    "        ca.append(i + '+')\n",
    "    else:\n",
    "        ca.append(str(i[:len(i)-2]) + '-' + i[-2:])\n",
    "\n",
    "df_tidy_4['age'] = ca\n",
    "df_tidy_5 = pd.DataFrame(df_tidy_4)      \n",
    "        \n",
    "print(df_tidy_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-794006afade645c7",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "column_names_hash = 'ab05d50deb2a842b806a607ad26166c82f91960bd9dae704d8a11ff78fb60860'\n",
    "dataframe_shape_hash = '78cdfddff871199ede18988405d0daf7c840512ff0bdb01168d3f85394618ef8'\n",
    "dataframe_hash = '324f52dadcd96598cd0edd64ce2ea6717aa7263a105a4b53b7ee5f6ea8baee30'\n",
    "\n",
    "assert isinstance(df_tidy_4, pd.DataFrame), \"df_tidy_5 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_5.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_5.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_5.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2cfdf1840adb37a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "Now that our dataset follows the Tidy Data principles, let's check for duplicates.\n",
    "\n",
    "Assign to variable `duplicates_count` the number of duplicates in `df_tidy_5`. Make sure the value you get is an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77ab90e009cd292d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of duplicates in df_tidy_5\n",
    "# duplicates_count = ...\n",
    "# YOUR CODE HERE\n",
    "duplicates = df_tidy_5.duplicated(keep='first')\n",
    "duplicates_count = int(duplicates.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b559fc483c9c8be1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "duplicates_count_hash = 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n",
    "\n",
    "error_msg = \"duplicates_count must be an integer (explicitly convert it to 'int' if it is type 'numpy.int64')\"\n",
    "assert isinstance(duplicates_count, int), error_msg\n",
    "\n",
    "error_msg = \"duplicates_count doesn't have the right value.\"\n",
    "assert duplicates_count_hash == hashlib.sha256(bytes(duplicates_count)).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec247ec84b19a9f6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Now let's count the number of rows with missing values in our `df_tidy_5` dataframe.\n",
    "\n",
    "Assign that value to variable `null_count` and make sure it is an integer.\n",
    "\n",
    "Also take a moment to think about the number of null values we had in this dataset, in comparison to the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-526e2589fa58add5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of null values in df_tidy_5\n",
    "# null_count = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "n_count_row = df_tidy_5.isnull().any(axis=1)\n",
    "null_count = int(n_count_row.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3da7144cdc77c7b9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "duplicates_count_hash = 'e41482b02884d9b42b5ea9abb63be3658c28266e8f62f31db33fc9efa53cf01d'\n",
    "\n",
    "error_msg = \"null_count must be an integer (explicitly convert it to 'int' if it is type 'numpy.int64')\"\n",
    "assert isinstance(null_count, int), error_msg\n",
    "\n",
    "error_msg = \"null_count doesn't have the right value.\"\n",
    "assert duplicates_count_hash == hashlib.sha256(bytes(null_count)).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f44322f1cee9fb4b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 9\n",
    "\n",
    "Now let's use a common technique to imput missing values: replacing them with the mean.\n",
    "\n",
    "Create a new dataframe `df_tidy_6`, which is a copy of `df_tidy_5`, except that the missing values in the `cases` column are replaced with the mean of the column.\n",
    "\n",
    "Also, take a moment to think if this is a good strategy in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      country  year       cases gender   age\n",
      "0          AD  1989  636.764374      m  0-14\n",
      "1          AD  1990  636.764374      m  0-14\n",
      "2          AD  1991  636.764374      m  0-14\n",
      "3          AD  1992  636.764374      m  0-14\n",
      "4          AD  1993  636.764374      m  0-14\n",
      "5          AD  1994  636.764374      m  0-14\n",
      "6          AD  1996    0.000000      m  0-14\n",
      "7          AD  1997    0.000000      m  0-14\n",
      "8          AD  1998    0.000000      m  0-14\n",
      "9          AD  1999    0.000000      m  0-14\n",
      "10         AD  2000    0.000000      m  0-14\n",
      "11         AD  2001    0.000000      m  0-14\n",
      "12         AD  2002    0.000000      m  0-14\n",
      "13         AD  2003    0.000000      m  0-14\n",
      "14         AD  2004    0.000000      m  0-14\n",
      "15         AD  2005    0.000000      m  0-14\n",
      "16         AD  2006    0.000000      m  0-14\n",
      "17         AD  2007  636.764374      m  0-14\n",
      "18         AD  2008    0.000000      m  0-14\n",
      "19         AE  1980  636.764374      m  0-14\n",
      "20         AE  1981  636.764374      m  0-14\n",
      "21         AE  1982  636.764374      m  0-14\n",
      "22         AE  1983  636.764374      m  0-14\n",
      "23         AE  1984  636.764374      m  0-14\n",
      "24         AE  1985  636.764374      m  0-14\n",
      "25         AE  1986  636.764374      m  0-14\n",
      "26         AE  1987  636.764374      m  0-14\n",
      "27         AE  1988  636.764374      m  0-14\n",
      "28         AE  1989  636.764374      m  0-14\n",
      "29         AE  1990  636.764374      m  0-14\n",
      "...       ...   ...         ...    ...   ...\n",
      "92274      ZM  2008    0.000000      f     u\n",
      "92275      ZW  1980  636.764374      f     u\n",
      "92276      ZW  1981  636.764374      f     u\n",
      "92277      ZW  1982  636.764374      f     u\n",
      "92278      ZW  1983  636.764374      f     u\n",
      "92279      ZW  1984  636.764374      f     u\n",
      "92280      ZW  1985  636.764374      f     u\n",
      "92281      ZW  1986  636.764374      f     u\n",
      "92282      ZW  1987  636.764374      f     u\n",
      "92283      ZW  1988  636.764374      f     u\n",
      "92284      ZW  1989  636.764374      f     u\n",
      "92285      ZW  1990  636.764374      f     u\n",
      "92286      ZW  1991  636.764374      f     u\n",
      "92287      ZW  1992  636.764374      f     u\n",
      "92288      ZW  1993  636.764374      f     u\n",
      "92289      ZW  1994  636.764374      f     u\n",
      "92290      ZW  1995  636.764374      f     u\n",
      "92291      ZW  1996  636.764374      f     u\n",
      "92292      ZW  1997  636.764374      f     u\n",
      "92293      ZW  1998  636.764374      f     u\n",
      "92294      ZW  1999  636.764374      f     u\n",
      "92295      ZW  2000  636.764374      f     u\n",
      "92296      ZW  2001  636.764374      f     u\n",
      "92297      ZW  2002  636.764374      f     u\n",
      "92298      ZW  2003  636.764374      f     u\n",
      "92299      ZW  2004  636.764374      f     u\n",
      "92300      ZW  2005  636.764374      f     u\n",
      "92301      ZW  2006  636.764374      f     u\n",
      "92302      ZW  2007  636.764374      f     u\n",
      "92303      ZW  2008    0.000000      f     u\n",
      "\n",
      "[92304 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_tidy_5['cases'] = df_tidy_5.cases.fillna(df_tidy_5.cases.mean())\n",
    "df_tidy_6 = pd.DataFrame(df_tidy_5)\n",
    "print(df_tidy_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91a85cda9755c1f5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a new version of df_tidy_5 where the cases missing values are replaced with the mean\n",
    "# df_tidy_6 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df_tidy_5['cases'] = df_tidy_5.cases.fillna(df_tidy_5.cases.mean())\n",
    "df_tidy_6 = pd.DataFrame(df_tidy_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5f3a449dd2f19c7d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "column_names_hash = 'ab05d50deb2a842b806a607ad26166c82f91960bd9dae704d8a11ff78fb60860'\n",
    "dataframe_shape_hash = '78cdfddff871199ede18988405d0daf7c840512ff0bdb01168d3f85394618ef8'\n",
    "dataframe_hash = '1f8e04b67a127979a1a47c9aac44716d9c08b9aa0d7641b7bb8542769a32db37'\n",
    "\n",
    "assert isinstance(df_tidy_6, pd.DataFrame), \"df_tidy_6 should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(df_tidy_6.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(df_tidy_6.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(df_tidy_6.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4e27258fc7f53fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 10\n",
    "\n",
    "Did you think that replacing the missing values with the mean was a terrible idea in this case? Because it is!\n",
    "\n",
    "Let's see why.\n",
    "\n",
    "Create a new dataframe `top_cases`, by:\n",
    "- sorting `df_tidy_5` by the cases column in descending order\n",
    "- taking the first row per country, using the drop_duplicates function\n",
    "- taking the first 10 rows of that dataframe\n",
    "\n",
    "Then take a look at the countries in `top_countries`. Can you see a correlation between the number of cases and the population size of those countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21d03667d23b1548",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with the rows that correspond to the 10 highest number of cases in df_tidy_5\n",
    "# top_cases = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "top_cases = pd.DataFrame()\n",
    "top_cases = top_cases.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-042e21c24cf691b9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The dataframe doesn't have the right columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-35e81e403372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The dataframe doesn't have the right columns.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mcolumn_names_hash\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_cases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_msg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0merror_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The dataframe doesn't have the right shape.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dataframe doesn't have the right columns."
     ]
    }
   ],
   "source": [
    "column_names_hash = 'ab05d50deb2a842b806a607ad26166c82f91960bd9dae704d8a11ff78fb60860'\n",
    "dataframe_shape_hash = '36d0cc685f3df22cfee85b856d878e734000d5cf3ff3cc3f809a96c623410ff4'\n",
    "dataframe_hash = '8420df6d826597ab69f60b0c1131a440908a1fbe7ed5abdb673c17040ad72f4a'\n",
    "\n",
    "assert isinstance(top_cases, pd.DataFrame), \"top_cases should be a pandas DataFrame.\"\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right columns.\"\n",
    "assert column_names_hash == hashlib.sha256(json.dumps(top_cases.columns.tolist()).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe doesn't have the right shape.\"\n",
    "assert dataframe_shape_hash == hashlib.sha256(json.dumps(top_cases.shape).encode()).hexdigest(), error_msg\n",
    "\n",
    "error_msg = \"The dataframe is not correct.\"\n",
    "assert dataframe_hash == hashlib.sha256(top_cases.to_msgpack()).hexdigest(), error_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28a762e168359bb3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 11 - ungraded\n",
    "\n",
    "Take some time to discuss with a coleague sitting next to you, what would be a better way to impute missing values in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
