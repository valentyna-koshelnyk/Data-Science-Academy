{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc148b069032ac72",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU16 - Data Sufficiency and Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73d0f28288cec5d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from hashlib import sha1 # just for grading purposes\n",
    "import json # just for grading purposes\n",
    "\n",
    "def _hash(obj):\n",
    "    if type(obj) is not str:\n",
    "        obj = json.dumps(obj)\n",
    "    return sha1(obj.encode()).hexdigest()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e47d27916830bf56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788678</td>\n",
       "      <td>-2.468043</td>\n",
       "      <td>-2.403158</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>-1.390815</td>\n",
       "      <td>-0.497524</td>\n",
       "      <td>-0.283922</td>\n",
       "      <td>-2.472916</td>\n",
       "      <td>Meerkat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.360423</td>\n",
       "      <td>-0.918873</td>\n",
       "      <td>0.880275</td>\n",
       "      <td>-0.646257</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>0.069273</td>\n",
       "      <td>-1.083448</td>\n",
       "      <td>-0.183893</td>\n",
       "      <td>Meerkat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.329499</td>\n",
       "      <td>-0.608535</td>\n",
       "      <td>-1.169760</td>\n",
       "      <td>0.517516</td>\n",
       "      <td>-1.630975</td>\n",
       "      <td>-1.046952</td>\n",
       "      <td>0.923580</td>\n",
       "      <td>-0.332124</td>\n",
       "      <td>Meerkat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.525361</td>\n",
       "      <td>-0.827992</td>\n",
       "      <td>-0.620789</td>\n",
       "      <td>-0.152414</td>\n",
       "      <td>-0.287303</td>\n",
       "      <td>1.846636</td>\n",
       "      <td>-0.676444</td>\n",
       "      <td>0.211721</td>\n",
       "      <td>Meerkat</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.158881</td>\n",
       "      <td>-1.094734</td>\n",
       "      <td>0.184125</td>\n",
       "      <td>-0.610730</td>\n",
       "      <td>0.073603</td>\n",
       "      <td>0.250729</td>\n",
       "      <td>-1.503690</td>\n",
       "      <td>0.612917</td>\n",
       "      <td>Meerkat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.788678  -2.468043  -2.403158   0.084746  -1.390815  -0.497524   \n",
       "1   1.360423  -0.918873   0.880275  -0.646257   0.087879   0.069273   \n",
       "2   1.329499  -0.608535  -1.169760   0.517516  -1.630975  -1.046952   \n",
       "3  -0.525361  -0.827992  -0.620789  -0.152414  -0.287303   1.846636   \n",
       "4  -0.158881  -1.094734   0.184125  -0.610730   0.073603   0.250729   \n",
       "\n",
       "   feature_6  feature_7 feature_8  id  \n",
       "0  -0.283922  -2.472916   Meerkat   0  \n",
       "1  -1.083448  -0.183893   Meerkat   1  \n",
       "2   0.923580  -0.332124   Meerkat   2  \n",
       "3  -0.676444   0.211721   Meerkat   3  \n",
       "4  -1.503690   0.612917   Meerkat   4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load up a classification dataset\n",
    "\n",
    "X = pd.read_csv('data/exercise_X.csv')\n",
    "y = pd.read_csv('data/exercise_y.csv')['label']\n",
    "# give X a quick look\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7ff45300c5ff1f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like a balanced binary target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2.000000\n",
       "mean     500.000000\n",
       "std      705.692568\n",
       "min        1.000000\n",
       "25%      250.500000\n",
       "50%      500.000000\n",
       "75%      749.500000\n",
       "max      999.000000\n",
       "Name: feature_8, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['feature_8'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd5e4f00e0c6d410",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the first obviously useless feature\n",
    "\n",
    "Can you determine which of the features contains all uniques and therefore cannot have any predictive power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "from utils import (\n",
    "    train_and_test, # function\n",
    "    train_and_test_logit, # function\n",
    "    produce_test_predictions, # function\n",
    "    encode_categoricals, # function\n",
    "    categoricals, # array of categorical feature names,\n",
    "    read_and_get_dummies, # read the titanic dataframe and create dummies\n",
    "    plot_learning_curve, # taken from sklearn website\n",
    ")\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this cell to determine which of the features serves as a categorical\n",
    "# feature and contains all uniques\n",
    "X.select_dtypes(['category']).nunique().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a584b7a530c36ed0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# set the variable feature_all_unique to the name of the feature\n",
    "# that contains all uniques\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "feature_all_unique = X.id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-805f4867b353fe96",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Series is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f35454182ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### BEGIN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_all_unique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'87ea5dfc8b8e384d848979496e706390b497e547'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m### END TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9c02e448a048>\u001b[0m in \u001b[0;36m_hash\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msha1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/slu16/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/slu16/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/slu16/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/anaconda3/envs/slu16/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Series is not JSON serializable"
     ]
    }
   ],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(feature_all_unique) == '87ea5dfc8b8e384d848979496e706390b497e547'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-602ec15412879335",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the second obviously useless feature\n",
    "\n",
    "This one doesn't contain all uniques but based upon some Single Factor Analysis you should be able to determine which feature isn't worth\n",
    "bothering with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to do some more SFA on other features to determine\n",
    "# which of them is useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f99bab2575793069",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to determine the other obviously useless feature\n",
    "other_useless_feature = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6964c9cd17f443b8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(other_useless_feature) == '04c03b252faf210d252b1d80590911758427b048'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-949c10443e311151",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# now drop the features that you determined to be useless and store them in X_1\n",
    "\n",
    "# X_1 = X.drop(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-476d75f82723fb0c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(list(sorted(X_1.columns))) == '7c9a6ed68a038fdcf0722571cbc6a60ed958d19b'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d29f316d3f5c61e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the rest of the useless features\n",
    "\n",
    "Single Factor Analysis isn't likely to do much in helping us to determine\n",
    "which of the rest of the features are useless. We'll need to some `feature_importances` in order to find the rest of these bad boys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6fbdfd50396e632f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now let's import and train the classifier and get the feature importance using\n",
    "# the X_1 DataFrame\n",
    "\n",
    "# First import a tree based classifier\n",
    "\n",
    "# from sklearn... import ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create your classifier, assign it to the clf variable and then\n",
    "# train it on X_1 and y\n",
    "clf = None\n",
    "\n",
    "# once the classifier is trained, set the feature importances here\n",
    "# make it a pandas series with the index being the column names\n",
    "# so that we can visualize the results\n",
    "feature_importances = None\n",
    "\n",
    "# set the random_state=1 and max_depth=5 or the tests won't pass!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ca84ae67d444979f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert hasattr(clf, 'feature_importances_'), 'The classifier must be a tree based classifier'\n",
    "assert clf.random_state == 1, 'random_state must be 1'\n",
    "assert clf.max_depth == 5, 'max_depth must be 5'\n",
    "assert np.isclose(feature_importances['feature_0'], 0.031820, atol=1e-5), 'feature 0 importance seems off'\n",
    "assert np.isclose(feature_importances['feature_1'], 0.128733, atol=1e-5), 'feature 1 importance seems off'\n",
    "assert np.isclose(feature_importances['feature_6'], 0.146977, atol=1e-5), 'feature 6 importance seems off'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-662fccd5e1566e6a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "feature_importances.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d91aeb204b6b8280",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now let's import and train the classifier and get the feature importance using\n",
    "# the X_1 DataFrame\n",
    "\n",
    "# First import a LogisticRegression\n",
    "\n",
    "# from sklearn... import ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create your classifier, assign it to the clf variable and then\n",
    "# train it on X_1 and y\n",
    "clf = None\n",
    "\n",
    "# once the classifier is trained, set the coefs_ here\n",
    "# make it a pandas series with the index being the column names\n",
    "# so that we can visualize the results\n",
    "# BE SURE to take the absolute value of the coefs\n",
    "abs_coefs = None\n",
    "\n",
    "# set the solver='lbfgs' and random_state=1 or the tests won't pass!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-21604081b6abb0ef",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert isinstance(clf, LogisticRegression), 'The classifier must be a logistic regression'\n",
    "assert clf.random_state == 1, 'random_state must be 1'\n",
    "assert clf.solver == 'lbfgs', 'solver must be lbfgs'\n",
    "assert np.isclose(abs_coefs['feature_0'], 0.031889, atol=1e-5), 'feature 0 coef seems off'\n",
    "assert np.isclose(abs_coefs['feature_1'], 0.093313, atol=1e-5), 'feature 1 coef seems off'\n",
    "assert np.isclose(abs_coefs['feature_6'], 0.405876, atol=1e-5), 'feature 6 coef seems off'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b4524fd9720e964",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "abs_coefs.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dc20755ad6d11ce",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# now remove the 3 remaining useless features and store them in\n",
    "# the variable X_2\n",
    "\n",
    "# X_2 = X_1.drop(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-47bb1f540f749a88",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(list(sorted(X_2.columns))) == '0ba088ebdcf2b8598c95a2a89cf140b86ec1d6d5'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd25a293de8f844d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Correlations\n",
    "\n",
    "Determine the correlations between each of the features and the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67f849ea5722ac92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/exercise_X.csv')\n",
    "y = pd.read_csv('data/exercise_y.csv')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-343f6f6aefebbb4e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, compute the absolute value of the correlations between each feature and the target and store it in\n",
    "# a variable called abs_corrs\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-83e620d736ca893b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "expected_features = {\n",
    "    'feature_0', \n",
    "    'feature_1', \n",
    "    'feature_2', \n",
    "    'feature_3', \n",
    "    'feature_4',\n",
    "    'feature_5',\n",
    "    'feature_6',\n",
    "    'feature_7',\n",
    "}\n",
    "assert set(abs_corrs.index) == expected_features, 'you should only have expected_features features'\n",
    "assert np.isclose(abs_corrs['feature_0'], 0.027928, rtol=1e-04)\n",
    "assert np.isclose(abs_corrs['feature_5'], 0.008327, rtol=1e-04)\n",
    "assert np.isclose(abs_corrs['feature_7'], 0.285048, rtol=1e-04)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-168fac9d07e35232",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# The learning curve\n",
    "\n",
    "Okay now that we have gotten rid of all those useless features, let's focus on getting a sense for how much data we need in order to have\n",
    "reasonable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f22e3c91b478ba32",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now create a dataframe that has a single feature that is the\n",
    "# cross validation score in order to help us understand\n",
    "# how increasing amounts of data affect the performance\n",
    "\n",
    "# HINT: just use the snippet from the Learning Notebook\n",
    "train_scores_mean = None\n",
    "test_scores_mean = None\n",
    "\n",
    "# instantiate a classifier that you will inspect the learning rate of\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "\n",
    "# IMPORTANT: Be sure to train on X_2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d1bded5a2e391786",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "# round in order to compensate for implementation details\n",
    "\n",
    "assert math.isclose(sum(train_scores_mean), 4.5, rel_tol=1e-2)\n",
    "assert math.isclose(sum(test_scores_mean), 3.8, rel_tol=1e-2)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b91ef37925959db9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "learning_curve_df = pd.DataFrame({\n",
    "    'Training Scores': train_scores_mean,\n",
    "    'Test Set scores': test_scores_mean\n",
    "}, index=train_sizes)\n",
    "\n",
    "learning_curve_df.plot.line(\n",
    "    title='Decision Tree Learning Curve'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc4e8393bc289ff2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now select the minimum training set size that this particular classifier\n",
    "# seems to need before it's learning rate stabilizes\n",
    "\n",
    "min_train_set_size = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1669e239252c8492",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(min_train_set_size) == 'ba30fd97b4127db56e9f4d3d9c030d71646fd2e7'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
