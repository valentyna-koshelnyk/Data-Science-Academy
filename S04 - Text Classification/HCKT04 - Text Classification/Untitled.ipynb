{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter, OrderedDict\n",
    "import re\n",
    "import string\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "irrelevant    31045\n",
       "debate         8909\n",
       "agree          3678\n",
       "clickbait       840\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upd = df[df.label != 'irrelevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‘Jihadi John’: The Islamic State killer behind...</td>\n",
       "      <td>LONDON — The identity of the masked executione...</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Report: Taliban Detainee Swapped for Bowe Berg...</td>\n",
       "      <td>A Guantanamo Bay prisoner released last year a...</td>\n",
       "      <td>debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Did Paul Rudd Help Take Down Dallas Airport Ho...</td>\n",
       "      <td>So… Rebecca Schoenkopf over at Wonkette is pre...</td>\n",
       "      <td>debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>US officials: Video shows American's execution</td>\n",
       "      <td>WARNING: GRAPHIC IMAGES. A masked militant cla...</td>\n",
       "      <td>debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Was The Video Of That Homeless Man Doing Good ...</td>\n",
       "      <td>Awwwww!\\nThis is such a heartwarming story!\\nW...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "4   ‘Jihadi John’: The Islamic State killer behind...   \n",
       "8   Report: Taliban Detainee Swapped for Bowe Berg...   \n",
       "9   Did Paul Rudd Help Take Down Dallas Airport Ho...   \n",
       "10     US officials: Video shows American's execution   \n",
       "11  Was The Video Of That Homeless Man Doing Good ...   \n",
       "\n",
       "                                                 text      label  \n",
       "4   LONDON — The identity of the masked executione...      agree  \n",
       "8   A Guantanamo Bay prisoner released last year a...     debate  \n",
       "9   So… Rebecca Schoenkopf over at Wonkette is pre...     debate  \n",
       "10  WARNING: GRAPHIC IMAGES. A masked militant cla...     debate  \n",
       "11  Awwwww!\\nThis is such a heartwarming story!\\nW...  clickbait  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df_upd['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(df_upd, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, stemmer, regex_list,\n",
    "                 lower=True, remove_punct=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X = list(map(self._clean_sentence, X))\n",
    "        return X\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "        # Split sentence into list of words\n",
    "        words = self.tokenizer.tokenize(sentence)\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "\n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            words = map(self.stemmer.stem, words)\n",
    "\n",
    "        # Join list elements into string\n",
    "        sentence = \" \".join(words)\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "regex_list = [(\"<[^>]*>\", \"\")\n",
    "             ]\n",
    "\n",
    "cleaner = TextCleanerTransformer(tokenizer, stemmer, regex_list)\n",
    "docs = cleaner.transform(train_df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small sample of the vocabulary: ['day', 'michael', 'brown', 'buri', 'ferguson', 'man', 'releas', 'claim', 'new', 'evid', 'case', 'cnn', 'report', 'audio', 'unnam', 'say', 'having', 'video', 'chat', 'woman']\n",
      "\n",
      "Number of distinct words: 15428\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(docs)\n",
    "\n",
    "# Looking at a small sample of the vocabulary:\n",
    "vocabulary = list(vectorizer.vocabulary_.keys())\n",
    "print(\"Small sample of the vocabulary:\", vocabulary[0:20])\n",
    "\n",
    "# Number of words in the vocabulary\n",
    "print(\"\\nNumber of distinct words:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the young soldier kill in a terror attack on the canadian parliament last night was a devot famili man and a career soldier who plan on becom a border guard by contrast his killer was a convict crimin who was on the terror watchlist and had his passport confisc it was chanc that brought the two men togeth when michael zehaf bibeau 32 launch his attack as corpor nathan cirillo 25 stood guard at ottawa ’ s war memori just metr away from the nation parliament zehaf bibeau shot corpor cirillo dead before run into parliament only to be kill himself by the sergeant at arm kevin vicker vicker sergeant at arm the hero of ottawa mr vicker has been hail as a hero after he dash into his offic to retriev a hand gun before shoot zehaf bibeau dead michael zehaf bibeau the gunman respons for the shoot imag credit cbcottawa michael zehaf bibeau shot dead nathan cirillo and storm parliament before being kill pictur from the twitter account of cbc ottawa canadian prime minist stephen harper declar the act a “ terror attack ” as he said that canadian would not be intimid by such action the attack had particular potenc with canada alreadi on alert because of a dead hit and run earlier in the week against two canadian soldier by muslim convert martin rouleau coutur corpor cirillo ’ s aunt has describ him as a “ wonder young man ,” who join the cadet in his hometown of hamilton as an adolesc and went on to enlist with the argyl and sutherland highland canberra copycat fear lock down parliament in a cruel twist he was carri out a short rotat of just one month as a guard at the war memori the posit was creat seven year ago after a string of vandal attempt the nation war memori which includ the tomb of the unknown soldier honour canadian who die for their countri “ he was a wonder young man not an enemi in the world ,” cpl cirillo ’ s aunt told the globe and mail newspap live ottawa parliament attack she said her nephew was devot to his six year old son and spent almost all of his spare time with his famili and work out she said “ he was into being fit and being a father and a son .” zehaf bibeau on the other hand had a crimin record in quebec and british columbia the son of a libyan mother and quebecois mother he has convict for drug possess and robberi he was recent design a “ high risk travel ” by the canadian govern and his passport was seiz ottawa ottawa attack on terror watchlist his mother susan is the deputi chairman of the immigr and refuge board of canada radio canada has report polic said in the initi hour after the shoot that as mani as two other gunmen may have taken part but as the day wore on the cordon around parliament was eas employe were allow to go home and the sens of urgenc appear to wane “ today is a sad and tragic day for our citi and our countri ,” ottawa mayor jim watson said he said it was a tragedi with “ origin as yet not fulli known caus not yet fulli understood .” wit said corpor cirillo was gun down at point blank rang just before 10 am by a man carri a rifl and dress all in black his face half cover they said the gunman appear to rais his arm in triumph then ran off and enter parliament a few hundr yard away where dozen of shot soon rang out defenc adf chief warn against complac peopl fled the complex by scrambl down scaffold erect for renov while other took cover insid and barricad door with chair as polic with rifl and bodi armour took up posit outsid and cordon off the normal bustl street around parliament video footag post onlin by the globe and mail newspap show polic duck for cover as they advanc along a stone hallway loud gunfir echo among parliament ’ s stone column report in canada said that if the gunman had turn left as he ran into the build he would have enter the room where a caucus meet was being held colonel geordi elm a former command offic of the argyl told the globe and mail that his “ heart just fell ” when he saw the regiment ’ s distinct gold leopard badg on the shot soldier on televis broadcast “ that could only be one unit ,” he said he thought at the time because the guard role is consid ceremoni mr cirillo ’ s gun probabl was not load he said hamilton mayor bob bratina told the newspap he had visit corpl cirillo ’ s famili who had told him that he was excit to be a part of the armi “ he was so proud of it ,” he said “ and look realli great wear the argyl kit .” ap afp \n",
      "\n",
      "10 :  1\n",
      "25 :  1\n",
      "32 :  1\n",
      "account :  1\n",
      "act :  1\n",
      "action :  1\n",
      "adf :  1\n",
      "adolesc :  1\n",
      "advanc :  1\n",
      "afp :  1\n",
      "ago :  1\n",
      "alert :  1\n",
      "allow :  1\n",
      "alreadi :  1\n",
      "ap :  1\n",
      "appear :  2\n",
      "argyl :  3\n",
      "arm :  3\n",
      "armi :  1\n",
      "armour :  1\n",
      "attack :  6\n",
      "attempt :  1\n",
      "aunt :  2\n",
      "away :  2\n",
      "badg :  1\n",
      "barricad :  1\n",
      "becom :  1\n",
      "bibeau :  6\n",
      "black :  1\n",
      "blank :  1\n",
      "board :  1\n",
      "bob :  1\n",
      "bodi :  1\n",
      "border :  1\n",
      "bratina :  1\n",
      "british :  1\n",
      "broadcast :  1\n",
      "brought :  1\n",
      "build :  1\n",
      "bustl :  1\n",
      "cadet :  1\n",
      "canada :  4\n",
      "canadian :  6\n",
      "canberra :  1\n",
      "career :  1\n",
      "carri :  2\n",
      "caucus :  1\n",
      "caus :  1\n",
      "cbc :  1\n",
      "cbcottawa :  1\n",
      "ceremoni :  1\n",
      "chair :  1\n",
      "chairman :  1\n",
      "chanc :  1\n",
      "chief :  1\n",
      "cirillo :  8\n",
      "citi :  1\n",
      "colonel :  1\n",
      "columbia :  1\n",
      "column :  1\n",
      "command :  1\n",
      "complac :  1\n",
      "complex :  1\n",
      "confisc :  1\n",
      "consid :  1\n",
      "contrast :  1\n",
      "convert :  1\n",
      "convict :  2\n",
      "copycat :  1\n",
      "cordon :  2\n",
      "corpl :  1\n",
      "corpor :  4\n",
      "countri :  2\n",
      "coutur :  1\n",
      "cover :  3\n",
      "cpl :  1\n",
      "creat :  1\n",
      "credit :  1\n",
      "crimin :  2\n",
      "cruel :  1\n",
      "dash :  1\n",
      "day :  2\n",
      "dead :  4\n",
      "declar :  1\n",
      "defenc :  1\n",
      "deputi :  1\n",
      "describ :  1\n",
      "design :  1\n",
      "devot :  2\n",
      "die :  1\n",
      "distinct :  1\n",
      "door :  1\n",
      "dozen :  1\n",
      "dress :  1\n",
      "drug :  1\n",
      "duck :  1\n",
      "earlier :  1\n",
      "eas :  1\n",
      "echo :  1\n",
      "elm :  1\n",
      "employe :  1\n",
      "enemi :  1\n",
      "enlist :  1\n",
      "enter :  2\n",
      "erect :  1\n",
      "excit :  1\n",
      "face :  1\n",
      "famili :  3\n",
      "father :  1\n",
      "fear :  1\n",
      "fell :  1\n",
      "fit :  1\n",
      "fled :  1\n",
      "footag :  1\n",
      "fulli :  2\n",
      "geordi :  1\n",
      "globe :  3\n",
      "gold :  1\n",
      "govern :  1\n",
      "great :  1\n",
      "guard :  4\n",
      "gun :  3\n",
      "gunfir :  1\n",
      "gunman :  3\n",
      "gunmen :  1\n",
      "hail :  1\n",
      "half :  1\n",
      "hallway :  1\n",
      "hamilton :  2\n",
      "hand :  2\n",
      "harper :  1\n",
      "heart :  1\n",
      "held :  1\n",
      "hero :  2\n",
      "high :  1\n",
      "highland :  1\n",
      "hit :  1\n",
      "home :  1\n",
      "hometown :  1\n",
      "honour :  1\n",
      "hour :  1\n",
      "hundr :  1\n",
      "imag :  1\n",
      "immigr :  1\n",
      "includ :  1\n",
      "initi :  1\n",
      "insid :  1\n",
      "intimid :  1\n",
      "jim :  1\n",
      "join :  1\n",
      "just :  4\n",
      "kevin :  1\n",
      "kill :  3\n",
      "killer :  1\n",
      "kit :  1\n",
      "known :  1\n",
      "launch :  1\n",
      "left :  1\n",
      "leopard :  1\n",
      "libyan :  1\n",
      "live :  1\n",
      "load :  1\n",
      "lock :  1\n",
      "look :  1\n",
      "loud :  1\n",
      "mail :  3\n",
      "man :  4\n",
      "mani :  1\n",
      "martin :  1\n",
      "mayor :  2\n",
      "meet :  1\n",
      "memori :  3\n",
      "men :  1\n",
      "metr :  1\n",
      "michael :  3\n",
      "minist :  1\n",
      "month :  1\n",
      "mother :  3\n",
      "mr :  2\n",
      "muslim :  1\n",
      "nathan :  2\n",
      "nation :  2\n",
      "nephew :  1\n",
      "newspap :  3\n",
      "night :  1\n",
      "normal :  1\n",
      "offic :  2\n",
      "old :  1\n",
      "onlin :  1\n",
      "origin :  1\n",
      "ottawa :  7\n",
      "outsid :  1\n",
      "parliament :  10\n",
      "particular :  1\n",
      "passport :  2\n",
      "peopl :  1\n",
      "pictur :  1\n",
      "plan :  1\n",
      "point :  1\n",
      "polic :  3\n",
      "posit :  2\n",
      "possess :  1\n",
      "post :  1\n",
      "potenc :  1\n",
      "prime :  1\n",
      "probabl :  1\n",
      "proud :  1\n",
      "quebec :  1\n",
      "quebecois :  1\n",
      "radio :  1\n",
      "rais :  1\n",
      "ran :  2\n",
      "rang :  2\n",
      "realli :  1\n",
      "recent :  1\n",
      "record :  1\n",
      "refuge :  1\n",
      "regiment :  1\n",
      "renov :  1\n",
      "report :  2\n",
      "respons :  1\n",
      "retriev :  1\n",
      "rifl :  2\n",
      "risk :  1\n",
      "robberi :  1\n",
      "role :  1\n",
      "room :  1\n",
      "rotat :  1\n",
      "rouleau :  1\n",
      "run :  2\n",
      "sad :  1\n",
      "said :  12\n",
      "saw :  1\n",
      "scaffold :  1\n",
      "scrambl :  1\n",
      "seiz :  1\n",
      "sens :  1\n",
      "sergeant :  2\n",
      "seven :  1\n",
      "shoot :  3\n",
      "short :  1\n",
      "shot :  4\n",
      "soldier :  5\n",
      "son :  3\n",
      "soon :  1\n",
      "spare :  1\n",
      "spent :  1\n",
      "stephen :  1\n",
      "stone :  2\n",
      "stood :  1\n",
      "storm :  1\n",
      "street :  1\n",
      "string :  1\n",
      "susan :  1\n",
      "sutherland :  1\n",
      "taken :  1\n",
      "televis :  1\n",
      "terror :  4\n",
      "thought :  1\n",
      "time :  2\n",
      "today :  1\n",
      "togeth :  1\n",
      "told :  4\n",
      "tomb :  1\n",
      "took :  2\n",
      "tragedi :  1\n",
      "tragic :  1\n",
      "travel :  1\n",
      "triumph :  1\n",
      "turn :  1\n",
      "twist :  1\n",
      "twitter :  1\n",
      "understood :  1\n",
      "unit :  1\n",
      "unknown :  1\n",
      "urgenc :  1\n",
      "vandal :  1\n",
      "vicker :  3\n",
      "video :  1\n",
      "visit :  1\n",
      "wane :  1\n",
      "war :  3\n",
      "warn :  1\n",
      "watchlist :  2\n",
      "watson :  1\n",
      "wear :  1\n",
      "week :  1\n",
      "went :  1\n",
      "wit :  1\n",
      "wonder :  2\n",
      "wore :  1\n",
      "work :  1\n",
      "world :  1\n",
      "yard :  1\n",
      "year :  2\n",
      "young :  3\n",
      "zehaf :  6\n"
     ]
    }
   ],
   "source": [
    "sentence = docs[12:13]\n",
    "print(sentence[0], '\\n')\n",
    "\n",
    "# Tranform sentence into bag of words representation\n",
    "word_count_sentence = vectorizer.transform(sentence)\n",
    "\n",
    "# Find the indexes of the words which appear in the sentence\n",
    "_, columns = word_count_sentence.nonzero()\n",
    "\n",
    "# Get the inverse map to map vector indexes to words\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "inv_map = {v: k for k, v in vocabulary.items()}\n",
    "\n",
    "# Extract the corresponding word and count\n",
    "counts = [(inv_map[i], word_count_sentence[0, i]) for i in columns]\n",
    "\n",
    "for word, count in counts:\n",
    "    print(word, \": \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13427, 15428)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_matrix = vectorizer.transform(df_upd['text'].values)\n",
    "word_count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf.fit(word_count_matrix)\n",
    "\n",
    "word_term_frequency_matrix = tfidf.transform(word_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44472, 450478)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_123_grams = CountVectorizer(stop_words= 'english', ngram_range=(1,3))\n",
    "vectorizer_123_grams.fit(docs)\n",
    "word_count_matrix = vectorizer_123_grams.transform(df['text'].values)\n",
    "word_count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
